{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Set som Globals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "PATH_RELATIVE = 'data/'\n",
    "LABEL = 'label_users_top_100'\n",
    "LABEL = 'label_bins'\n",
    "LABEL = 'label_time_encoded'\n",
    "LABEL_MODEL = 'Responsible'\n",
    "LABEL_MODEL = 'Time-Bins'\n",
    "LABEL_MODEL = 'Time-Encoded'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Loading in the model and tokenizer\n",
    "The `from_pretrained` parameter can simply be changed to the saved output folder if you wan't to\n",
    "continue training an already fine-tuned model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFXLMRobertaForSequenceClassification were initialized from the model checkpoint at data/models/IHLP-XLM-RoBERTa-Time-Encoded.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(f'{PATH_RELATIVE}models/IHLP-XLM-RoBERTa-{LABEL_MODEL}')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label\n",
      "50534  oprettelse af ny ansat: pmmoeller (start: --) ...    483\n",
      "50535  side via biblioteket melder om fejl (ddos prot...    117\n",
      "50536  problem hello, i have a problem. on fridayi ha...    473\n",
      "50537                                  bestilling kabler    133\n",
      "50538  luk/nedlg sdu-ansat: nicoline lyck bech, nbech...    482\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{PATH_RELATIVE}cached_test_{LABEL}.csv')\n",
    "df = df[-1000:]\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def tokenize_texts(sentences, max_length=512, padding='max_length'):\n",
    "    return tokenizer(\n",
    "        sentences,\n",
    "        truncation=False,\n",
    "        padding=padding,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "tokenized_text = dict(tokenize_texts(list(df['text'].values)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.838249921798706, 0.5440000295639038]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10)])\n",
    "results = model.evaluate(tokenized_text, df.label.values, batch_size=16, verbose=False)\n",
    "\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}